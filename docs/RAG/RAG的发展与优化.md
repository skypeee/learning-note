## 一、朴素 RAG（Naive RAG）🔰

> 初始阶段，追求“能用”，适合快速验证想法

### 目标：

实现一个最小可用版本（MVP）的问答系统，能结合文档进行准确回答。

### 架构组成：

1. **静态文档库**：事先准备的知识文件（如产品文档、书籍等）
2. **嵌入生成**：用开源 embedding 模型（如 `sentence-transformers`) 把文档切块编码成向量
3. **向量索引**：用 FAISS 构建本地检索数据库
4. **问题编码**：将用户问题编码为向量
5. **相似度检索**：用 top-k 相似度召回文档
6. **prompt 拼接**：将召回文档和问题拼接输入大语言模型（如 GPT）
7. **生成答案**

### 架构流程：

1. **Question**：用户输入一个自然语言问题。
2. **Retriever**：基于向量相似度检索相关文档（如通过 FAISS 检索 top-k 文档）。
3. **Document Collection**：将这些被召回的文档组织起来（可以是原文、摘要或片段）。
4. **Generator**：将用户问题与相关文档拼接成 prompt 输入给 LLM。
5. **Answer**：大模型生成最终答案。

### 特点总结：

- 简单直接，但存在：

  - **文档无排序**
  - **检索精度不高**
  - **无法处理复杂多轮对话**

### 特点：

- 易上手，适合原型验证
- 单轮问答为主
- 精度有限，存在“幻觉”风险
- 检索不可解释、排序较粗糙

---

### 二、进阶 RAG（Advanced RAG）📈

> 结构增强，提升准确性、灵活性和用户体验

#### 新增能力：

在朴素 RAG 基础上，引入 **多阶段检索、上下文理解、prompt 控制、评估机制** 等能力。

#### 架构增强：

| 模块                  | 优化方式                                                     |
| ----------------------- | -------------------------------------------------------------- |
| 检索增强（Retriever） | 加入 Reranker（如 BGE Reranker）、Hybrid 检索（向量+关键词） |
| 嵌入优化              | 使用更强的模型（如`bge-base`,`e5-mistral`）                                        |
| 多轮对话支持          | 通过 query rewriter 重构用户追问，实现上下文连贯             |
| Prompt 设计           | 分层提示 + Chain-of-Thought，引导模型“思考”                |
| 检索片段控制          | 基于 chunk overlap、滑动窗口控制片段粒度                     |
| 评估机制              | 使用 RAGAS、Faithfulness Score、用户反馈进行评估             |

### 架构新增模块：

1. **Reranker**：对初步召回的文档进行排序（例如用 BGE-Reranker/BERT-Reranker），提升准确性。
2. **Retrieved Documents**：只保留高质量的片段（例如 top-3）。
3. **Generator**：基于更干净、更相关的文档生成答案。

### 变化说明：

- 检索不再是“拿来就用”，而是经过 **二次筛选**。
- 更强调  **“高质量输入换来高质量输出”** 。

### 特点总结：

- 加入 **语义排序机制**
- 更适合回答细粒度问题
- 支持部分上下文管理（如 query rewrite）

#### 特点：

- 多轮问答能力
- 更强检索准确性（减少幻觉）
- Prompt 更稳健，响应更贴切
- 可组合多数据源
- 开始关注“用户体验”

---

### 三、模块化 RAG（Modular / Industrial RAG）🏗️

> 面向**可维护、可扩展、可部署**的企业级架构设计

#### 设计理念：

每个核心能力单独成模块，具备“可替换性 + 插拔性”，系统可以灵活扩展、升级和部署。

### 架构模块进一步分离：

1. **Query Encoder**：将自然语言问题转换为向量（可支持自定义 embedding 模型）。
2. **Reranker**：更智能的 rerank 模块，可以结合检索得分、上下文、语境等信息。
3. **Contextualization**：

    - 将召回文档根据任务目的进行再组织（如摘要、过滤、对齐格式）。
    - 甚至支持结构化组织（如 JSON prompt）。
4. **Generator**：使用标准或企业部署的大模型（如 GPT、Claude、Mistral 等）。
5. **Answer**：最终响应用户请求。

### 核心优势：

- 每个模块**可独立部署/测试/替换**（例如换用更强的 reranker、嵌入模型等）
- 支持微调、A/B 测试、日志追踪
- 易于运维扩展，适合接入企业数据系统

#### 模块化组成（面向架构层）：

| 模块名称            | 功能说明                                                   | 示例工具/框架                    |
| --------------------- | ------------------------------------------------------------ | ---------------------------------- |
| 文档管道（Ingest）  | 文档预处理、清洗、分块、Embedding 更新                     | LlamaIndex、Haystack             |
| 向量索引层          | 构建与维护向量检索引擎，支持增量更新与热更新               | FAISS、Weaviate、Qdrant          |
| 检索器（Retriever） | 支持 Hybrid 检索、Rerank、可插拔 query 改写                | LangChain Retriever、ColBERT     |
| 上下文构建器        | 拼接上下文、prompt 设计器、加入结构提示语                  | 自定义、LangChain PromptTemplate |
| 生成器（Generator） | 封装 LLM 接口，支持模型切换（如 OpenAI / Mistral / Llama） | OpenAI API、Transformers         |
| 对话管理器          | 支持多轮问答、记忆、历史检索等                             | LangChain Memory、RAGFusion      |
| 日志监控与评估      | 请求记录、性能监控、用户反馈整合                           | TruLens、Promptfoo、RAGAS        |
| 缓存层              | 检索缓存 / 回答缓存，加速响应                              | Redis、Pinecone Cache Layer      |

#### 特点：

- **组件高度解耦，可插拔**
- **支持模型/检索多后端切换**
- **便于部署和运维（Docker、K8s）**
- **支持对接企业数据、身份权限控制**
- **具备 A/B 测试能力和质量评估闭环**

---